{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMmsYW/6mjkI0F7CFQkJ9GA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"seODVoU4fZom"},"outputs":[],"source":["import torch\n","\n","# as 'model' is T5ForConditionalGeneration object\n","torch.save(model.state_dict(), 'resume_ranking_model.pth')\n","# Save the model's state dictionary to a .pth file\n"]},{"cell_type":"code","source":["!pip install ngrok\n","!pip install PyMuPDF  # For PDF processing"],"metadata":{"id":"YcnZrhb6fg4x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ngrok config add-authtoken 2nQ3pFBFq91lamPkHw4T36dfCKO_6GK37BkB4QxSqLBqUUPvq"],"metadata":{"id":"Rk7bTRSQfjf-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pyngrok import ngrok\n","# Terminate any existing tunnels\n","ngrok.kill()\n","\n","# Start a new tunnel for port 8501 (Streamlit's default port)\n","# Use 'addr' instead of 'port' for specifying the address\n","public_url = ngrok.connect(addr='8501')\n","print(f\"Streamlit public URL: {public_url}\")"],"metadata":{"id":"BFveoiTSfjmo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%writefile app.py\n","import streamlit as st\n","import pandas as pd\n","import numpy as np\n","from sklearn.ensemble import RandomForestClassifier\n","import joblib\n","from transformers import T5ForConditionalGeneration, T5Tokenizer\n","import fitz  # PyMuPDF for PDF processing\n","\n","# Load the pre-trained T5 model and tokenizer\n","model = T5ForConditionalGeneration.from_pretrained('t5-base')\n","tokenizer = T5Tokenizer.from_pretrained('t5-base')\n","\n","# Load the pre-trained Random Forest model\n","clf = joblib.load('resume_ranking_model.pkl')  # Adjust the path as necessary\n","\n","def predict_score(resume_features):\n","    \"\"\"Predict the hiring score based on resume features.\"\"\"\n","    # Get the prediction probability for the 'hired' class\n","    score = clf.predict_proba([resume_features])[0][1]  # Get probability of being hired\n","    return score\n","\n","def explain_ranking(resume_features):\n","    \"\"\"Provide insights into ranking based on features.\"\"\"\n","    explanation = f\"Similarity: {resume_features[0]}, Experience: {resume_features[1]} years, Skills Match: {resume_features[2]}\"\n","    return explanation\n","\n","def extract_text_from_pdf(pdf_file):\n","    \"\"\"Extract text from a PDF file.\"\"\"\n","    text = \"\"\n","    with fitz.open(pdf_file) as doc:\n","        for page in doc:\n","            text += page.get_text()\n","    return text\n","\n","# Streamlit App\n","st.title('AI-Powered Resume Ranking System')\n","\n","# Upload Job Description\n","uploaded_jd = st.file_uploader(\"Upload Job Description (txt file)\", type=[\"txt\"])\n","uploaded_cvs = st.file_uploader(\"Upload CVs (pdf file)\", type=[\"pdf\"], accept_multiple_files=True)\n","\n","if uploaded_jd and uploaded_cvs:\n","    # Read the job description\n","    jd_text = uploaded_jd.read().decode(\"utf-8\")\n","\n","    results = []\n","\n","    # Process each PDF CV\n","    for uploaded_cv in uploaded_cvs:\n","        cv_text = extract_text_from_pdf(uploaded_cv)\n","\n","        # we can further process cv_text to extract specific information, e.g., experience, skills\n","        # For this example, we'll create mock values for demonstration\n","        similarity = np.random.uniform(0.5, 1.0)  # Replace with actual similarity calculation\n","        experience_years = 5  # Replace with actual extracted value\n","        skills_match = 1  # Replace with actual extracted value\n","\n","        # Create feature set\n","        resume_features = [similarity, experience_years, skills_match]\n","\n","        # Predict the score\n","        score = predict_score(resume_features)\n","\n","        # Generate feedback using T5\n","        input_text = f\"Generate feedback for the resume with similarity {similarity}, experience {experience_years}, skills match {skills_match}.\"\n","        input_ids = tokenizer.encode(input_text, return_tensors='pt')\n","        outputs = model.generate(input_ids)\n","        feedback = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","        results.append((uploaded_cv.name, score))\n","\n","    # Display results\n","    results_df = pd.DataFrame(results, columns=[\"CV File Name\", \"Score\"])\n","    st.write(\"Ranking Results:\")\n","    st.dataframe(results_df)\n","\n","    # Allow download of results\n","    st.write(\"Download Ranking Results:\")\n","    st.download_button(\"Download CSV\", results_df.to_csv(index=False), \"ranked_resumes.csv\")\n"],"metadata":{"id":"EAd3xphafjr4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!streamlit run app.py & npx localtunnel --port 8501"],"metadata":{"id":"bstb6AJpfrj-"},"execution_count":null,"outputs":[]}]}