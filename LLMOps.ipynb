{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMGLBlxxIfWnjI1IBTkZJba"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"082KaDQ9eN-8"},"outputs":[],"source":["from transformers import T5ForConditionalGeneration, T5Tokenizer\n","\n","# Load pre-trained T5 model and tokenizer from Hugging Face\n","tokenizer = T5Tokenizer.from_pretrained('t5-base')\n","model = T5ForConditionalGeneration.from_pretrained('t5-base')\n","\n","# Function to generate feedback using T5\n","def generate_feedback(resume_text, jd_text):\n","    # Create input for the model\n","    input_text = f\"compare: {resume_text} to job: {jd_text}\"\n","\n","    # Tokenize input text\n","    input_ids = tokenizer(input_text, return_tensors='pt').input_ids\n","\n","    # Generate feedback\n","    feedback_ids = model.generate(input_ids, max_length=50)\n","    feedback = tokenizer.decode(feedback_ids[0], skip_special_tokens=True)\n","\n","    return feedback\n","\n","\n","feedback = generate_feedback(resume, job_description)\n","print(f\"Feedback: {feedback}\")\n"]}]}