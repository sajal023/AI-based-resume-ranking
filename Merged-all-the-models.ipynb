{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPrPAURFk/qnm2+Gd7aRJ12"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install sentence-transformers\n","!pip install mlflow\n","!pip install openai==0.28\n","!pip install fastapi\n","!pip install streamlit\n","!pip install pyngrok\n","!pip install transformers\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nlVOlx-Ypczy","executionInfo":{"status":"ok","timestamp":1728896054808,"user_tz":-330,"elapsed":47950,"user":{"displayName":"Sajal Srivastav","userId":"09375067762183460039"}},"outputId":"7f7fbb1a-f06e-481d-da65-ce3c353d9fab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.0)\n","Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.44.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.5)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.4.1+cu121)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n","Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.24.7)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (10.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.19.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n","Requirement already satisfied: mlflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n","Requirement already satisfied: mlflow-skinny==2.17.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.17.0)\n","Requirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.5)\n","Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.13.3)\n","Requirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (7.1.0)\n","Requirement already satisfied: graphene<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.3)\n","Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7)\n","Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7.1)\n","Requirement already satisfied: numpy<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.26.4)\n","Requirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.2)\n","Requirement already satisfied: pyarrow<18,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (16.1.0)\n","Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.5.2)\n","Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.13.1)\n","Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.35)\n","Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.4)\n","Requirement already satisfied: gunicorn<24 in /usr/local/lib/python3.10/dist-packages (from mlflow) (23.0.0)\n","Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (5.5.0)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (8.1.7)\n","Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (2.2.1)\n","Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (0.34.0)\n","Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (3.1.43)\n","Requirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (8.4.0)\n","Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (1.27.0)\n","Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (1.27.0)\n","Requirement already satisfied: packaging<25 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (24.1)\n","Requirement already satisfied: protobuf<6,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (3.20.3)\n","Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (6.0.2)\n","Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (2.32.3)\n","Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.0->mlflow) (0.5.1)\n","Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.5)\n","Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (4.12.2)\n","Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker<8,>=4.0.0->mlflow) (2.2.3)\n","Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (3.0.4)\n","Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (2.2.0)\n","Requirement already satisfied: graphql-core<3.3,>=3.1 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow) (3.2.5)\n","Requirement already satisfied: graphql-relay<3.3,>=3.1 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow) (3.2.0)\n","Requirement already satisfied: aniso8601<10,>=8 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow) (9.0.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow) (2.1.5)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.4.7)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (10.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (3.1.4)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2024.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (3.5.0)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n","Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.10/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (2.27.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.17.0->mlflow) (4.0.11)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.17.0->mlflow) (3.20.2)\n","Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow) (1.2.14)\n","Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow) (0.48b0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib<4->mlflow) (1.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.0->mlflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.0->mlflow) (3.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.0->mlflow) (2024.8.30)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow) (1.16.0)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.17.0->mlflow) (5.0.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (0.4.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (4.9)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (0.6.1)\n","Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n","Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.5)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.10.9)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.8.30)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.13.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n","Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28) (4.12.2)\n","Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (0.115.2)\n","Requirement already satisfied: starlette<0.41.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.39.2)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.9.2)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.12.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.23.4)\n","Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.41.0,>=0.37.2->fastapi) (3.7.1)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.41.0,>=0.37.2->fastapi) (3.10)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.41.0,>=0.37.2->fastapi) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.41.0,>=0.37.2->fastapi) (1.2.2)\n","Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.39.0)\n","Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n","Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n","Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n","Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n","Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n","Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.2.2)\n","Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (10.4.0)\n","Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n","Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (16.1.0)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n","Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.2)\n","Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n","Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n","Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n","Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.9.1)\n","Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n","Requirement already satisfied: watchdog<6,>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.0.3)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.20.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n","Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.0)\n","Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score"],"metadata":{"id":"NHLgx-pfCcjq"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ViFHX216pOtQ","executionInfo":{"status":"ok","timestamp":1728896948241,"user_tz":-330,"elapsed":3680,"user":{"displayName":"Sajal Srivastav","userId":"09375067762183460039"}},"outputId":"b8e30adb-6fa0-4d36-cdf2-b7e1bab73657"},"outputs":[{"output_type":"stream","name":"stdout","text":["Semantic Similarity Score: 0.10290748625993729\n"]}],"source":["import spacy\n","from sentence_transformers import SentenceTransformer, util\n","\n","# Load spaCy model for Named Entity Recognition (NER)\n","nlp = spacy.load('en_core_web_sm')\n","\n","# Load SentenceTransformer for semantic similarity\n","semantic_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n","\n","# Function to preprocess text (tokenization, stopword removal, etc.)\n","def preprocess_text(text):\n","    doc = nlp(text)\n","    tokens = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n","    return ' '.join(tokens)\n","\n","# Function to calculate semantic similarity\n","def calculate_similarity(resume_text, jd_text):\n","    resume_embedding = semantic_model.encode(resume_text, convert_to_tensor=True)\n","    jd_embedding = semantic_model.encode(jd_text, convert_to_tensor=True)\n","    similarity = util.pytorch_cos_sim(resume_embedding, jd_embedding).item()\n","    return similarity\n","\n","# Preprocess and calculate similarity\n","processed_resume = preprocess_text(resume)\n","processed_jd = preprocess_text(job_description)\n","similarity_score = calculate_similarity(processed_resume, processed_jd)\n","\n","print(f\"Semantic Similarity Score: {similarity_score}\")\n"]},{"cell_type":"code","source":["import joblib\n","# Additional features for resume ranking\n","experience_years = 5  # Assume this is extracted from the resume\n","skills_match = 1      # Assume skills match is binary: 1 (match), 0 (no match)\n","\n","# Prepare the dataset for training Random Forest\n","data =pd.read_csv(\"/content/large_mock_resume_data.csv\")\n","df = pd.DataFrame(data)\n","\n","# Split dataset into train and test sets\n","X = df[['similarity', 'experience_years', 'skills_match']]\n","y = df['hired']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","print(X_train)\n","# Train Random Forest Classifier\n","clf = RandomForestClassifier(n_estimators=100, random_state=42)\n","clf.fit(X_train, y_train)\n","\n","# Predictions\n","y_pred = clf.predict(X_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","\n","print(f\"Model Accuracy: {accuracy}\")\n","\n","# Prediction for the current resume (using the example features)\n","new_resume_features = pd.DataFrame({\n","    'similarity': [similarity_score],\n","    'experience_years': [experience_years],\n","    'skills_match': [skills_match]\n","})\n","print(new_resume_features)\n","predicted_hire = clf.predict(new_resume_features)\n","print(f\"Resume Hire Prediction: {'Hired' if predicted_hire[0] == 1 else 'Not Hired'}\")\n","\n","joblib.dump(clf, 'resume_ranking_model.pkl')  # Save the model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F-jH9X3-psCb","executionInfo":{"status":"ok","timestamp":1728896999146,"user_tz":-330,"elapsed":940,"user":{"displayName":"Sajal Srivastav","userId":"09375067762183460039"}},"outputId":"c83fc046-43c1-4a76-f102-8562c212d0a9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["     similarity  experience_years  skills_match\n","29     0.523225                18             1\n","535    0.972383                17             1\n","695    0.805310                12             1\n","557    0.514391                 9             0\n","836    0.957423                18             0\n","..          ...               ...           ...\n","106    0.705191                13             1\n","270    0.904681                19             1\n","860    0.887764                14             1\n","435    0.850485                16             1\n","102    0.657178                 7             1\n","\n","[800 rows x 3 columns]\n","Model Accuracy: 0.51\n","   similarity  experience_years  skills_match\n","0    0.102907                 5             1\n","Resume Hire Prediction: Not Hired\n"]},{"output_type":"execute_result","data":{"text/plain":["['resume_ranking_model.pkl']"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["import mlflow\n","import mlflow.sklearn\n","\n","# Start MLflow run\n","with mlflow.start_run():\n","    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n","    clf.fit(X_train, y_train)\n","\n","    y_pred = clf.predict(X_test)\n","    accuracy = accuracy_score(y_test, y_pred)\n","\n","    # Log metrics and model\n","    mlflow.log_metric(\"accuracy\", accuracy)\n","    mlflow.sklearn.log_model(clf, \"resume_ranking_model\")\n","\n","    print(f\"Logged Model Accuracy: {accuracy}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DSx_MCD2pzFH","executionInfo":{"status":"ok","timestamp":1728897012804,"user_tz":-330,"elapsed":9389,"user":{"displayName":"Sajal Srivastav","userId":"09375067762183460039"}},"outputId":"2954e62e-84ee-4051-fbc4-a2d7df109daa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2024/10/14 09:10:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"]},{"output_type":"stream","name":"stdout","text":["Logged Model Accuracy: 0.51\n"]}]},{"cell_type":"code","source":["from transformers import T5ForConditionalGeneration, T5Tokenizer\n","\n","# Load pre-trained T5 model and tokenizer from Hugging Face\n","tokenizer = T5Tokenizer.from_pretrained('t5-base')\n","model = T5ForConditionalGeneration.from_pretrained('t5-base')\n","\n","# Function to generate feedback using T5\n","def generate_feedback(resume_text, jd_text):\n","    # Create input for the model\n","    input_text = f\"compare: {resume_text} to job: {jd_text}\"\n","\n","    # Tokenize input text\n","    input_ids = tokenizer(input_text, return_tensors='pt').input_ids\n","\n","    # Generate feedback\n","    feedback_ids = model.generate(input_ids, max_length=50)\n","    feedback = tokenizer.decode(feedback_ids[0], skip_special_tokens=True)\n","\n","    return feedback\n","\n","\n","feedback = generate_feedback(resume, job_description)\n","print(f\"Feedback: {feedback}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IKU2-K_9qC93","executionInfo":{"status":"ok","timestamp":1728897021608,"user_tz":-330,"elapsed":5674,"user":{"displayName":"Sajal Srivastav","userId":"09375067762183460039"}},"outputId":"2f882ca0-68b8-43b6-9eac-ce0afdca4489"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Feedback: : resume2.txt.pdf to: resume2.txt.pdf to job: Looking for a data scientist proficient in Python and deep learning.\n"]}]},{"cell_type":"code","source":["import os\n","\n","def rank_resumes(jd_text, resume_files):\n","    rankings = []\n","    for resume_file in resume_files:\n","        resume_file_path = os.path.join(\"/content/resume1.txt\", resume_file)\n","        with open(resume_file, 'r',encoding='latin-1') as file:\n","            resume_text = file.read()\n","            processed_resume = preprocess_text(resume_text)\n","            score = calculate_similarity(processed_resume, jd_text)\n","            rankings.append((resume_file, score))\n","\n","    # Sort resumes by score\n","    rankings.sort(key=lambda x: x[1], reverse=True)\n","    return rankings\n","\n","# Example Input/Output\n","job_description = \"Looking for a data scientist proficient in Python and deep learning.\"\n","resume_files = ['resume1.txt.pdf', 'resume2.txt.pdf', 'resume3.txt.pdf']\n","ranked_resumes = rank_resumes(job_description, resume_files)\n","\n","for resume, score in ranked_resumes:\n","    print(f\"Resume: {resume}, Score: {score}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lUHz6Dm8tpy0","executionInfo":{"status":"ok","timestamp":1728897078617,"user_tz":-330,"elapsed":53075,"user":{"displayName":"Sajal Srivastav","userId":"09375067762183460039"}},"outputId":"44a5bc59-cff3-42da-e9df-5ca96c4fd79c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Resume: resume3.txt.pdf, Score: 0.1084691733121872\n","Resume: resume1.txt.pdf, Score: 0.05133873224258423\n","Resume: resume2.txt.pdf, Score: 0.030292704701423645\n"]}]},{"cell_type":"code","source":["import torch\n","\n","# as 'model' is T5ForConditionalGeneration object\n","torch.save(model.state_dict(), 'resume_ranking_model.pth')\n","# Save the model's state dictionary to a .pth file\n"],"metadata":{"id":"AMTTOKFZFdHL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install ngrok\n","!pip install PyMuPDF  # For PDF processing"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6uw4BUV7-xIl","executionInfo":{"status":"ok","timestamp":1728896430729,"user_tz":-330,"elapsed":8512,"user":{"displayName":"Sajal Srivastav","userId":"09375067762183460039"}},"outputId":"8f79796a-086b-4cdb-dde0-d209b2252ddb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: ngrok in /usr/local/lib/python3.10/dist-packages (1.4.0)\n","Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.10/dist-packages (1.24.11)\n"]}]},{"cell_type":"code","source":["!ngrok config add-authtoken 2nQ3pFBFq91lamPkHw4T36dfCKO_6GK37BkB4QxSqLBqUUPvq"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728897421144,"user_tz":-330,"elapsed":1069,"user":{"displayName":"Sajal Srivastav","userId":"09375067762183460039"}},"outputId":"99da80ff-6de5-4798-870d-ded8be1da513","id":"FyjiDGeL_WZs"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"]}]},{"cell_type":"code","source":["from pyngrok import ngrok\n","# Terminate any existing tunnels\n","ngrok.kill()\n","\n","# Start a new tunnel for port 8501 (Streamlit's default port)\n","# Use 'addr' instead of 'port' for specifying the address\n","public_url = ngrok.connect(addr='8501')\n","print(f\"Streamlit public URL: {public_url}\")"],"metadata":{"id":"psQwLkBd9oi2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728897424849,"user_tz":-330,"elapsed":1033,"user":{"displayName":"Sajal Srivastav","userId":"09375067762183460039"}},"outputId":"06916e21-7644-4171-c3e0-52245c2456c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Streamlit public URL: NgrokTunnel: \"https://50f3-34-142-255-107.ngrok-free.app\" -> \"http://localhost:8501\"\n"]}]},{"cell_type":"code","source":["%%writefile app.py\n","import streamlit as st\n","import pandas as pd\n","import numpy as np\n","from sklearn.ensemble import RandomForestClassifier\n","import joblib\n","from transformers import T5ForConditionalGeneration, T5Tokenizer\n","import fitz  # PyMuPDF for PDF processing\n","\n","# Load the pre-trained T5 model and tokenizer\n","model = T5ForConditionalGeneration.from_pretrained('t5-base')\n","tokenizer = T5Tokenizer.from_pretrained('t5-base')\n","\n","# Load the pre-trained Random Forest model\n","clf = joblib.load('resume_ranking_model.pkl')  # Adjust the path as necessary\n","\n","def predict_score(resume_features):\n","    \"\"\"Predict the hiring score based on resume features.\"\"\"\n","    # Get the prediction probability for the 'hired' class\n","    score = clf.predict_proba([resume_features])[0][1]  # Get probability of being hired\n","    return score\n","\n","def explain_ranking(resume_features):\n","    \"\"\"Provide insights into ranking based on features.\"\"\"\n","    explanation = f\"Similarity: {resume_features[0]}, Experience: {resume_features[1]} years, Skills Match: {resume_features[2]}\"\n","    return explanation\n","\n","def extract_text_from_pdf(pdf_file):\n","    \"\"\"Extract text from a PDF file.\"\"\"\n","    text = \"\"\n","    with fitz.open(pdf_file) as doc:\n","        for page in doc:\n","            text += page.get_text()\n","    return text\n","\n","# Streamlit App\n","st.title('AI-Powered Resume Ranking System')\n","\n","# Upload Job Description\n","uploaded_jd = st.file_uploader(\"Upload Job Description (txt file)\", type=[\"txt\"])\n","uploaded_cvs = st.file_uploader(\"Upload CVs (pdf file)\", type=[\"pdf\"], accept_multiple_files=True)\n","\n","if uploaded_jd and uploaded_cvs:\n","    # Read the job description\n","    jd_text = uploaded_jd.read().decode(\"utf-8\")\n","\n","    results = []\n","\n","    # Process each PDF CV\n","    for uploaded_cv in uploaded_cvs:\n","        cv_text = extract_text_from_pdf(uploaded_cv)\n","\n","        # we can further process cv_text to extract specific information, e.g., experience, skills\n","        # For this example, we'll create mock values for demonstration\n","        similarity = np.random.uniform(0.5, 1.0)  # Replace with actual similarity calculation\n","        experience_years = 5  # Replace with actual extracted value\n","        skills_match = 1  # Replace with actual extracted value\n","\n","        # Create feature set\n","        resume_features = [similarity, experience_years, skills_match]\n","\n","        # Predict the score\n","        score = predict_score(resume_features)\n","\n","        # Generate feedback using T5\n","        input_text = f\"Generate feedback for the resume with similarity {similarity}, experience {experience_years}, skills match {skills_match}.\"\n","        input_ids = tokenizer.encode(input_text, return_tensors='pt')\n","        outputs = model.generate(input_ids)\n","        feedback = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","        results.append((uploaded_cv.name, score))\n","\n","    # Display results\n","    results_df = pd.DataFrame(results, columns=[\"CV File Name\", \"Score\"])\n","    st.write(\"Ranking Results:\")\n","    st.dataframe(results_df)\n","\n","    # Allow download of results\n","    st.write(\"Download Ranking Results:\")\n","    st.download_button(\"Download CSV\", results_df.to_csv(index=False), \"ranked_resumes.csv\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1mQbCz7fAYCy","executionInfo":{"status":"ok","timestamp":1728897430753,"user_tz":-330,"elapsed":604,"user":{"displayName":"Sajal Srivastav","userId":"09375067762183460039"}},"outputId":"d2dac87c-0d39-4b8e-adf9-94da86468aca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting app.py\n"]}]},{"cell_type":"code","source":["!streamlit run app.py & npx localtunnel --port 8501\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uZFmuiaQAegT","outputId":"d21a8329-e2dd-49f1-c544-885f6d99dc24","executionInfo":{"status":"ok","timestamp":1728899247330,"user_tz":-330,"elapsed":1811047,"user":{"displayName":"Sajal Srivastav","userId":"09375067762183460039"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n","\u001b[0m\n","\u001b[0m\n","\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n","\u001b[0m\n","\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n","\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n","\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.142.255.107:8501\u001b[0m\n","\u001b[0m\n","your url is: https://real-parks-rule.loca.lt\n","You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/root/.npm/_npx/75ac80b86e83d4a2/node_modules/localtunnel/bin/lt.js:81\n","    throw err;\n","    ^\n","\n","Error: connection refused: localtunnel.me:32209 (check your firewall settings)\n","    at Socket.<anonymous> (/root/.npm/_npx/75ac80b86e83d4a2/node_modules/\u001b[4mlocaltunnel\u001b[24m/lib/TunnelCluster.js:52:11)\n","\u001b[90m    at Socket.emit (node:events:513:28)\u001b[39m\n","\u001b[90m    at emitErrorNT (node:internal/streams/destroy:157:8)\u001b[39m\n","\u001b[90m    at emitErrorCloseNT (node:internal/streams/destroy:122:3)\u001b[39m\n","\u001b[90m    at processTicksAndRejections (node:internal/process/task_queues:83:21)\u001b[39m\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","\u001b[34m  Stopping...\u001b[0m\n"]}]}]}